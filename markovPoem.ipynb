{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markovPoem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZKhNg8481CA"
      },
      "source": [
        "#MARKOV CHAIN POETRY GENERATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcUx5fH989sU"
      },
      "source": [
        "### A **Markov Chain** is a mathematical process/system that transitions from one state to another according to probabilistic rules. Essentially, it's building a sequence based on probabilities. \n",
        "\n",
        "### The ***Natural Language Processing (NLP)** manifestation of this is something people interact with all the time: the predictive text function on our phones OR Google's auto-complete searching guess the next word based on probabilities of that word following the ones before it. <br>= Links on a chain \n",
        "\n",
        "***Natural Language Processing (NLP)** is the sub-domain / application of AI that deals with natural language. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwRa6t4k_fFT"
      },
      "source": [
        "##Start coding! Access Data & Prep It\n",
        "Before we build the machine, we need to import the tools that the code will need for its different tasks. In the Python coding language, these are called libraries.\n",
        "<br>**random**: will let the machine pick a random word from a list\n",
        "<br>**json**: will let the machine read a json formatted file\n",
        "<br>**string**: \n",
        "<br>**google.colab - drive:** lets us access filess from this google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8fW2KKY0D1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c48f1dd-add8-4b96-bc29-0b20ea4bf245"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import sys\n",
        "import string\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQoXBkTF-0oL"
      },
      "source": [
        "The next step is accessing and preparing/processing the dataset we want to use as background. For this demo, we are using all the scripts of the cartoon, *Rick & Morty*. Using this dataset will inform both the **Vocabulary** and the **Next-Word Probability** calculations of the output.\n",
        "\n",
        "This natural language dataset has a very *loud* flavor. Take a minute to imagine a poem composed only from the language of a sci-fi/fantasy, philosophical, somewhat dystopian, and rather R-rated television show. \n",
        "\n",
        "Now consider how that would compare to the dataset of language behind Apple products' predictive texting.\n",
        "\n",
        "**BIG IDEA:** The dataset we *curate* to inform our Markov Chain Poetry Generator significantly affects the output poem.\n",
        "\n",
        "To prepare this dataset for our generator, I've opted to remove punctuation and line breaks, then make all wods lower case so we don't get separate words for e.g. 'Spring' and 'spring'. The last step in processing is to turn our text into a list of words and remove any digits.\n",
        "\n",
        "Now, as a test let's just print the first 15 words in our dataset's list of words as well just to see how things look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34COLZoy-ygE"
      },
      "source": [
        "#Open dataset\n",
        "fodder = open('/content/drive/My Drive/Colab Notebooks/rickMorty_corpus.txt', 'r').read()\n",
        "\n",
        "#Process Text by removing punctuation and any double line breaks. Then make all words lowercase\n",
        "fodder = fodder.translate(str.maketrans('', '', string.punctuation))\n",
        "fodder = fodder.lower()\n",
        "\n",
        "#Split text by space into individual words will create a list of all words and removes digits\n",
        "fodder = ''.join([i for i in fodder if not i.isdigit()]).replace(\"\\n\\n\", \" \").replace(\"\\r\",\" \").split(' ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRzOiP8zzALH"
      },
      "source": [
        "Now that we have all the Rick & Morty scripts turned into a clean list of words in order of appearance, a list we've called 'fodder', let's find out how long this list is (how many words it has) and print the first 25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw2jq2CbzRDy",
        "outputId": "919c6522-946d-4726-e6a1-ca7ddf9c68c0"
      },
      "source": [
        "print (\"Number of words: \",len(fodder))\n",
        "print (\"First 25 words: \", fodder[0:25])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words:  228465\n",
            "First 25 words:  ['love', 'connection', 'experience', 'yeah', 'come', 'together', 'with', 'love', 'connection', 'and', 'experience', 'its', 'my', 'favorite', 'song', 'oh', 'yeah', 'oh', 'yeah', 'distress', 'beacon', 'yeah', 'baby', 'youre', 'excited']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1iuEdTzrc2u"
      },
      "source": [
        "## Coding the Building Blocks of our Markov Chain\n",
        "This next piece of code is a 'Loop' that allows us to iterate through each individual word of the list we created above. \n",
        "\n",
        "With each word looped through, we add to what is called a 'Dictionary'. Here, our dictionary is titled, \"chain\"\n",
        "Each entry in this dictionary is a unique word from our dataset and it is defined by a list of words that follow it. In Python, we call these entries and their definitions, *keys* and *values*. \n",
        "\n",
        "Run the chunk of code below and it will build our dictionary then print the entry for 'timeline' to show you an example. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8slYGz2re42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3e76f3-54c3-414e-8f2b-e5e2d253e2ed"
      },
      "source": [
        "index = 1\n",
        "chain = {}\n",
        "\n",
        "for word in fodder[index:]: \n",
        "  key = fodder[index - 1]\n",
        "  if key in chain:\n",
        "    chain[key].append(word)\n",
        "  else:\n",
        "    chain[key] = [word]\n",
        "  index += 1\n",
        "\n",
        "print (chain['theres'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'a', 'a', 'a', 'a', 'no', 'a', 'a', 'a', 'a', 'a', 'no', 'a', 'a', 'a', 'no', 'a', 'a', 'not', 'no', 'two', 'two', 'theres', 'a', 'our', 'not', 'no', 'two', 'two', 'theres', 'a', 'our', 'a', 'no', 'no', 'an', 'nothing', 'a', 'no', 'no', 'an', 'nothing', 'your', 'your', 'so', 'so', 'a', 'more', 'only', 'a', 'something', 'so', 'so', 'a', 'more', 'only', 'a', 'something', 'nothing', 'only', 'gotta', 'no', 'a', 'a', 'nothing', 'only', 'gotta', 'no', 'a', 'a', 'something', 'a', 'a', 'another', 'still', 'plenty', 'not', 'no', 'something', 'a', 'a', 'another', 'still', 'plenty', 'not', 'no', 'a', 'little', 'a', 'little', 'pros', 'caterers', 'nothing', 'got', 'always', 'flies', 'pros', 'caterers', 'nothing', 'got', 'always', 'flies', 'gonna', 'no', 'six', 'no', 'seven', 'some', 'only', 'always', 'four', 'six', 'only', 'a', 'been', 'gonna', 'no', 'six', 'no', 'seven', 'some', 'only', 'always', 'four', 'six', 'only', 'a', 'been', 'a', 'more', 'a', 'a', 'people', 'too', 'the', 'a', 'more', 'a', 'a', 'people', 'too', 'the', 'no', 'no', 'a', 'supposed', 'a', 'no', 'no', 'a', 'supposed', 'a', 'a', 'more', 'someone', 'a', 'a', 'more', 'someone', 'a', 'no', 'not', 'a', 'no', 'no', 'not', 'a', 'no', 'pictures', 'nothing', 'lots', '', 'no', 'pictures', 'nothing', 'lots', '', 'no', 'no', 'something', 'like', 'this', 'some', 'no', 'something', 'like', 'this', 'some', 'an', 'a', 'not', 'not', 'something', 'something', 'an', 'a', 'not', 'not', 'something', 'something', 'a', 'no', 'infinite', 'still', 'a', 'no', 'infinite', 'still', 'a', 'crucial', 'fruit', 'seeds', 'nothing', 'just', 'ways', 'no', 'a', 'crucial', 'fruit', 'seeds', 'nothing', 'just', 'ways', 'no', 'a', 'no', 'no', 'a', 'no', 'someone', 'our', 'a', 'no', 'no', 'a', 'no', 'someone', 'our', 'no', 'no', 'no', 'no', 'too', 'no', 'no', 'the', 'too', 'no', 'no', 'the', 'no', 'three', 'a', 'a', 'a', '', 'a', 'no', 'three', 'a', 'a', 'a', '', 'a', 'not', 'booby', 'gonna', 'no', 'a', 'no', 'nothing', 'no', 'not', 'booby', 'gonna', 'no', 'a', 'no', 'nothing', 'no', 'not', 'no', 'something', 'always', 'no', 'no', 'an', 'still', 'not', 'no', 'something', 'always', 'no', 'no', 'an', 'still', 'no', 'a', 'one', 'only', 'too', 'no', 'a', 'one', 'only', 'too', 'another', 'eight', 'only', 'a', 'an', 'several', 'no', 'another', 'eight', 'only', 'a', 'an', 'several', 'no', 'nothing', 'no', 'no', 'only', 'not', 'a', 'nothing', 'no', 'no', 'only', 'not', 'a', 'my', 'an', 'no', 'nothing', 'my', 'an', 'no', 'nothing', 'evidence', 'nowhere', 'a', 'little', 'any', 'evidence', 'nowhere', 'a', 'little', 'any']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS7Jhg_4s5NA"
      },
      "source": [
        "Our dictionary building worked! In the example, we can see that the word 'timeline' appeared in our dataset 10 different times, followed by the words 'I', 'fun', and 'all' twice each, then the word 'where' four times. \n",
        "\n",
        "If we save this dictionary, \"Chain\", to a file we can look at it more closely, and also make any edits we may want to our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmV8whkOtKzn"
      },
      "source": [
        "with open('output_chain.json', 'w') as fp:\n",
        "  json.dump(chain, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moUOnhAitMr7"
      },
      "source": [
        "Now that you've saved the output_chain file, take a moment to open it up and look through it. \n",
        "\n",
        "Find the dictionary key \"is\" by ctrl-F searching for the characters:<br>\n",
        "**\"spring\":**\n",
        "<br>You will see that this key has the values [at, at]<br>\n",
        "Try adding the value **is** to that list so it looks like:<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyuJ4h3ks5fT"
      },
      "source": [
        "#open and load the output_chain\n",
        "f = open('output_chain.json',)\n",
        "# returns JSON object as a dictionary\n",
        "data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVJ2RKO08VvK"
      },
      "source": [
        "## Compose a Line based on the Dictionary of Next-Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyC4O0UYuLnW"
      },
      "source": [
        "Here is where you can put a line you want to translate into *Rick&Morty-speak*. <br>\n",
        "\n",
        "For this demo, I'm using the first line of the e.e. cummings poem, \"Spring is like a perhaps hand\".\n",
        "\n",
        "Then I ask the machine to use the first word of the line to initialize our chain. Each word is added, one link at a time based on a the word preceding it. \n",
        "\n",
        "I.E. the machine looks for the first word, *spring*, in our dictionary and then picks - at random - a word from spring's list of next-words. Once it selects a 2nd word, it goes to *that* word's entry in our dictionary and selects a 3rd word from the 2nd word's list of next-words. It keeps repeating this process until we reach the number of words in the original line.\n",
        "\n",
        "Then it prints out our full line. You can keep running this code-chunk until you land on a line you like. Kind of like rolling the dice again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z54Qi0v_uLyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2151ac03-23e9-4f1c-a403-2165761798ae"
      },
      "source": [
        "line = 'spring is like a sometimes hand'\n",
        "line = line.split(\" \")\n",
        "index = 1\n",
        "chain = {}\n",
        "count = len(line)\n",
        "\n",
        "word1 = line[0]\n",
        "output = word1.capitalize()\n",
        "\n",
        "while len(output.split(' ')) < count:\n",
        "\t\tword2 = random.choice(data[word1])\n",
        "\t\tword1 = word2\n",
        "\t\toutput += ' ' + word2\n",
        "\n",
        "print (output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spring at me summer this is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYbU_sqs8n9m"
      },
      "source": [
        "## Compose a Whole Poem at Once\n",
        "If we want to compose a whole poem at once, rather than line by line, we can put all the lines together into a list variable, then 'loop' through each of those lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O79hy_998tdv",
        "outputId": "9ddfd845-9f86-4f46-eba1-79af58c86fb4"
      },
      "source": [
        "lines = ['spring is like a perhaps hand', \n",
        "'which comes carefully', \n",
        "'out of Nowhere arranging',\n",
        "'a window into which people look while',\n",
        "'people stare',\n",
        "'arrange and changing placing',\n",
        "'carefully there a strange',\n",
        "'thing and a known thing here and',\n",
        "'changing everything carefully']\n",
        "\n",
        "for line in lines: \n",
        "\tline = line.split(\" \")\n",
        "\tindex = 1\n",
        "\tchain = {}\n",
        "\tcount = len(line)\n",
        "\tword1 = line[0]\n",
        "\t#OR word1 = random.choice(list(chain.keys())) #random first word\n",
        "\tmessage = word1.capitalize()\n",
        "\t#Picks the next word over and over until word count achieved\n",
        "\twhile len(message.split(' ')) < count:\n",
        "\t\tword2 = random.choice(data[word1])\n",
        "\t\tword1 = word2\n",
        "\t\tmessage += ' ' + word2\n",
        "\n",
        "\tprint (message)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spring at my wallet and you\n",
            "Which clearly i\n",
            "Out um simple freedom\n",
            "A space with my god damn right\n",
            "People just\n",
            "Arrange her which point\n",
            "Carefully i will fall\n",
            "Thing come true and then kill each\n",
            "Changing timelines precludes\n"
          ]
        }
      ]
    }
  ]
}